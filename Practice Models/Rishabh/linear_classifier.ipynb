{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the saved arrow file\n",
    "dataset = Dataset.from_file('/Users/icon1c/Documents/Semester 2/Natural Language Processing/NLP-Polimi-Project/Practice Models/Rishabh/dataset/train/data-00000-of-00001.arrow')\n",
    "\n",
    "# Convert to Pandas DataFrame for analysis\n",
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "X = df['input']\n",
    "y = df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing data\n",
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for different models\n",
    "param_grids = {\n",
    "    'logistic_regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "for model_name, param_grid in param_grids.items():\n",
    "    if model_name == 'logistic_regression':\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif model_name == 'svm':\n",
    "        model = SVC()\n",
    "    elif model_name == 'random_forest':\n",
    "        model = RandomForestClassifier()\n",
    "    \n",
    "    clf = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    results[model_name] = {'accuracy': accuracy, 'f1': f1, 'best_params': clf.best_params_, 'y_pred': y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "    print(f\"F1-score: {result['f1']:.2f}\")\n",
    "    print(f\"Best hyperparameters: {result['best_params']}\")\n",
    "    print()\n",
    "    \n",
    "    # Detailed evaluation\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, result['y_pred']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, result['y_pred'])\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
